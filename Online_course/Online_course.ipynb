{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15fb6dc1-a47a-476c-8fdb-d1d9fd4c39fb",
   "metadata": {},
   "source": [
    "# Модель, прогнозирующая успешность прохождения обучения студентов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e079cf7-99f2-4727-aebd-f031a2f1ee32",
   "metadata": {},
   "source": [
    "### Цели и задачи проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1d9005-545e-4b22-be50-dc0b3dffd898",
   "metadata": {},
   "source": [
    "Цель: используя данные о первых двух днях на онлайн-курсе, предсказать, наберет ли пользователь 40 и более баллов. Качество модели оценить по метрике ROC-AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899f2848-4b29-4741-91fd-8cc51c340b15",
   "metadata": {},
   "source": [
    "### Описание данных\n",
    "\n",
    "`events_train.csv` - данные о действиях, которые совершают студенты со стэпами\n",
    "\n",
    "- `step_id` - id стэпа\n",
    "- `user_id` - анонимизированный id юзера\n",
    "- `timestamp` - время наступления события в формате unix date\n",
    "- `action` - событие, возможные значения: \n",
    "    - `discovered` - пользователь перешел на стэп\n",
    "    - `viewed` - просмотр шага,\n",
    "    - `started_attempt` - начало попытки решить шаг, ранее нужно было явно нажать на кнопку - начать решение, перед тем как приступить к решению практического шага\n",
    "    - `passed` - удачное решение практического шага\n",
    "\n",
    "\n",
    "`submissions_train.csv` - данные о времени и статусах сабмитов к практическим заданиям\n",
    "\n",
    "- `step_id` - id стэпа\n",
    "- `timestamp` - время отправки решения в формате unix date\n",
    "- `submission_status` - статус решения\n",
    "- `user_id` - анонимизированный id юзера"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2c7e7c-26c0-46cb-84a2-9189f40d1403",
   "metadata": {},
   "source": [
    "### Содержимое проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1534ca89-faad-4a96-874a-51b319909fa5",
   "metadata": {},
   "source": [
    "1. Загрузка данных и знакомство с ними.\n",
    "2. Предобработка данных и подготовка их к исследованию.\n",
    "3. Формирование и тестирование моделей.\n",
    "4. Общий вывод и рекомендации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef98baf0-6d03-478d-a61a-5b1e5a397ad7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Загрузка данных и знакомство с ними"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7c37846-9ad4-46a2-b071-100dd1f05431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Библиотеки для обработки и анализа данных\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Cтатистический анализ\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Библиотека для работы со временем  \n",
    "from time import time         \n",
    "\n",
    "# Библиотеки машинного обучения\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier                               \n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Глобальные настройки\n",
    "pd.options.mode.copy_on_write = True\n",
    "RANDOM_STATE = 9\n",
    "CV_FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e10533be-d93f-45ff-a659-b2410ce72edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем данные\n",
    "events_df = pd.read_csv('...')\n",
    "subm_df = pd.read_csv('...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cbddd01-d0d6-48d9-95b5-f58a4e2c71de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Информация о датасете events_df\n",
      "================================================== \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3480703 entries, 0 to 3480702\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Dtype \n",
      "---  ------     ----- \n",
      " 0   step_id    int64 \n",
      " 1   timestamp  int64 \n",
      " 2   action     object\n",
      " 3   user_id    int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 106.2+ MB\n",
      "None \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>action</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32815</td>\n",
       "      <td>1434340848</td>\n",
       "      <td>viewed</td>\n",
       "      <td>17632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32815</td>\n",
       "      <td>1434340848</td>\n",
       "      <td>passed</td>\n",
       "      <td>17632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32815</td>\n",
       "      <td>1434340848</td>\n",
       "      <td>discovered</td>\n",
       "      <td>17632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32811</td>\n",
       "      <td>1434340895</td>\n",
       "      <td>discovered</td>\n",
       "      <td>17632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32811</td>\n",
       "      <td>1434340895</td>\n",
       "      <td>viewed</td>\n",
       "      <td>17632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step_id   timestamp      action  user_id\n",
       "0    32815  1434340848      viewed    17632\n",
       "1    32815  1434340848      passed    17632\n",
       "2    32815  1434340848  discovered    17632\n",
       "3    32811  1434340895  discovered    17632\n",
       "4    32811  1434340895      viewed    17632"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Информация о датасете subm_df\n",
      "================================================== \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 509104 entries, 0 to 509103\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Non-Null Count   Dtype \n",
      "---  ------             --------------   ----- \n",
      " 0   step_id            509104 non-null  int64 \n",
      " 1   timestamp          509104 non-null  int64 \n",
      " 2   submission_status  509104 non-null  object\n",
      " 3   user_id            509104 non-null  int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 15.5+ MB\n",
      "None \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>submission_status</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31971</td>\n",
       "      <td>1434349275</td>\n",
       "      <td>correct</td>\n",
       "      <td>15853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31972</td>\n",
       "      <td>1434348300</td>\n",
       "      <td>correct</td>\n",
       "      <td>15853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31972</td>\n",
       "      <td>1478852149</td>\n",
       "      <td>wrong</td>\n",
       "      <td>15853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31972</td>\n",
       "      <td>1478852164</td>\n",
       "      <td>correct</td>\n",
       "      <td>15853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31976</td>\n",
       "      <td>1434348123</td>\n",
       "      <td>wrong</td>\n",
       "      <td>15853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step_id   timestamp submission_status  user_id\n",
       "0    31971  1434349275           correct    15853\n",
       "1    31972  1434348300           correct    15853\n",
       "2    31972  1478852149             wrong    15853\n",
       "3    31972  1478852164           correct    15853\n",
       "4    31976  1434348123             wrong    15853"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Создаем словарь датафреймов\n",
    "dic_df = {\n",
    "    'events_df': events_df,\n",
    "    'subm_df': subm_df\n",
    "}\n",
    "\n",
    "# Выводим информацию о датасетах и первые строки.\n",
    "for name, dfs in dic_df.items():\n",
    "    print('=' * 50)\n",
    "    print(f'Информация о датасете {name}')\n",
    "    print('=' * 50, '\\n')\n",
    "    print(dfs.info(), '\\n')\n",
    "    display(dfs.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66e281bf-a236-463e-a1a3-26c5d4601ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================\n",
      "Анализ пропущенных значений в events_df\n",
      "=========================================================================\n",
      "           Без пропусков  Кол-во пропусков  Процент пропусков (%)\n",
      "step_id          3480703                 0                    0.0\n",
      "timestamp        3480703                 0                    0.0\n",
      "action           3480703                 0                    0.0\n",
      "user_id          3480703                 0                    0.0 \n",
      "\n",
      "=========================================================================\n",
      "Анализ пропущенных значений в subm_df\n",
      "=========================================================================\n",
      "                   Без пропусков  Кол-во пропусков  Процент пропусков (%)\n",
      "step_id                   509104                 0                    0.0\n",
      "timestamp                 509104                 0                    0.0\n",
      "submission_status         509104                 0                    0.0\n",
      "user_id                   509104                 0                    0.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Подсчитываем процент строк с пропусками\n",
    "for name, dfs in dic_df.items():\n",
    "    print('=' * 73)    \n",
    "    print(f'Анализ пропущенных значений в {name}')\n",
    "    print('=' * 73) \n",
    "    \n",
    "    missing_df = pd.DataFrame({\n",
    "        'Без пропусков': dfs.notna().sum(),\n",
    "        'Кол-во пропусков': dfs.isna().sum(),\n",
    "        'Процент пропусков (%)': round(dfs.isna().mean() * 100, 1)\n",
    "    })\n",
    "    \n",
    "    print(missing_df, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7452c6ab-5c9e-4c73-b0d9-c01307f5632b",
   "metadata": {},
   "source": [
    "Данные загружены, пропусков нет."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c80980-111a-4a00-b91a-fc0529ff37f4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Предобработка данных и подготовка их к исследованию"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9300a8e5-b8f4-43df-9958-d7b8bbbf9167",
   "metadata": {},
   "source": [
    "- Проверим на дубликаты и удалим при наличии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c422457-8305-4ee7-bda7-5d43c31f5a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество полных дубликатов в events_df: 2333 строк.\n",
      "Процент удаленных строк events_df: 0.07%\n"
     ]
    }
   ],
   "source": [
    "print(f'Количество полных дубликатов в events_df: {events_df.duplicated().sum()} строк.')\n",
    "\n",
    "nodup_events_df = events_df.drop_duplicates().reset_index(drop=True)\n",
    "print(f'Процент удаленных строк events_df: {round((1 - len(nodup_events_df) / len(events_df)) * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b64beb02-080a-4bf3-b772-f98d65db15dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество полных дубликатов subm_df: 107 строк.\n",
      "Процент удаленных строк в subm_df: 0.02%\n"
     ]
    }
   ],
   "source": [
    "print(f'Количество полных дубликатов subm_df: {subm_df.duplicated().sum()} строк.')\n",
    "\n",
    "nodup_subm_df = subm_df.drop_duplicates().reset_index(drop=True)\n",
    "print(f'Процент удаленных строк в subm_df: {round((1 - len(nodup_subm_df) / len(subm_df)) * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed415ec-0790-4999-8e02-fe64ff13b7d2",
   "metadata": {},
   "source": [
    "- Преобразование типов данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad913873-2440-4af9-949d-17412c0e8f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodup_events_df['date'] = pd.to_datetime(nodup_events_df['timestamp'], unit='s')\n",
    "nodup_subm_df['date'] = pd.to_datetime(nodup_subm_df['timestamp'], unit='s')\n",
    "\n",
    "nodup_events_df['day'] = pd.to_datetime(nodup_events_df['timestamp'], unit='s').dt.date\n",
    "nodup_subm_df['day'] = pd.to_datetime(nodup_subm_df['timestamp'], unit='s').dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb3d7fc-fa45-4194-9c0e-5e5c08b06db9",
   "metadata": {},
   "source": [
    "Сформируем таблицу с пользователями и данными о том набрали они 40 и более баллов или нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b177fcb-906d-4aed-985d-70943375bc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = (\n",
    "    nodup_subm_df[nodup_subm_df['submission_status']=='correct']\n",
    "        .groupby('user_id')\n",
    "        .agg(more_40=('step_id', 'nunique')\n",
    "            )\n",
    "        .reset_index()\n",
    ")\n",
    "\n",
    "total_df['more_40'] = np.where(total_df['more_40']>=40, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2476a2-a425-4d93-841e-0c053c1df8a9",
   "metadata": {},
   "source": [
    "Отфильтруем данные в таблице с событиями за первые два дня."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "118cf9d6-304e-40b0-bfb0-b2571bdda6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Два дня в секундах\n",
    "period = (60 * 60 * 24) * 2\n",
    "\n",
    "# Фильтруем события за первые два дня в nodup_events_df\n",
    "nodup_events_df['first_date'] = nodup_events_df.groupby('user_id')['date'].transform('min')\n",
    "events_2d_df = nodup_events_df[(nodup_events_df['date'] - nodup_events_df['first_date']).dt.total_seconds()<=period]\n",
    "\n",
    "# Фильтруем события за первые два дня в nodup_subm_df\n",
    "nodup_subm_df['first_date'] = nodup_subm_df.groupby('user_id')['date'].transform('min')\n",
    "subm_2d_df = nodup_subm_df[(nodup_subm_df['date'] - nodup_subm_df['first_date']).dt.total_seconds()<=period]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95aa53bd-dac9-4e50-b650-a12aee2a37a6",
   "metadata": {},
   "source": [
    "Формируем признаки для обучения модели из таблицы событий по первым двум дням активности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8204b929-eded-472c-8c9d-a05d39d85a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.DataFrame()\n",
    "feature_df = (\n",
    "    pd.get_dummies(events_2d_df, columns=['action'], dtype=int)\n",
    "        .groupby('user_id')\n",
    "        .agg(\n",
    "            nuniq_steps_events=('step_id', 'nunique'),\n",
    "            cnt_discovered=('action_discovered', 'sum'),\n",
    "            cnt_passed=('action_passed', 'sum'),\n",
    "            cnt_started_attempt=('action_started_attempt', 'sum'),\n",
    "            cnt_viewed=('action_viewed', 'sum'),\n",
    "            nuniq_days_events=('day', 'nunique')\n",
    "        )\n",
    "        .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c629994-a580-4ea9-b13f-73bd218899dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем таблицу признаков в датасет для обучения\n",
    "total_df = total_df.merge(feature_df, on='user_id', how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459c640c-f834-4d92-be25-b738bc9f999e",
   "metadata": {},
   "source": [
    "Сформируем таблицу с признаками из таблицы прохождения тестов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61d9c3e5-b70b-4bad-9cbc-259ffa727a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_2d_df['last_step'] = subm_2d_df.groupby('user_id')['step_id'].transform('max')\n",
    "subm_2d_df['first_step'] = subm_2d_df.groupby('user_id')['step_id'].transform('min')\n",
    "\n",
    "temp_df = pd.get_dummies(subm_2d_df, columns=['submission_status'], dtype=int)\n",
    "\n",
    "# Формируем таблицу признаков\n",
    "feature_df = (\n",
    "    temp_df[temp_df['step_id']==temp_df['last_step']]\n",
    "        .groupby('user_id')\n",
    "        .agg(            \n",
    "            correct_on_last_step=('submission_status_correct', 'sum'),\n",
    "            wrong_on_last_step=('submission_status_wrong', 'sum')\n",
    "        )\n",
    "        .reset_index()\n",
    ")\n",
    "\n",
    "# Добавляем таблицу признаков в датасет для обучения\n",
    "total_df = total_df.merge(feature_df, on='user_id', how='outer').fillna(0)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cae92e4b-dc4e-4cad-a3e5-d8f70b26e938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Формируем таблицу признаков\n",
    "feature_df = (\n",
    "    temp_df[temp_df['step_id']==temp_df['first_step']]\n",
    "        .groupby('user_id')\n",
    "        .agg(\n",
    "            correct_on_first_step=('submission_status_correct', 'sum'),\n",
    "            wrong_on_first_step=('submission_status_wrong', 'sum')\n",
    "            )\n",
    "        .reset_index()\n",
    ")\n",
    "\n",
    "# Добавляем таблицу признаков в датасет для обучения\n",
    "total_df = total_df.merge(feature_df, on='user_id', how='outer').fillna(0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffdd6d4d-ecf3-4b3a-84be-138b4d58dc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Формируем таблицу признаков\n",
    "feature_df = (\n",
    "    pd.get_dummies(subm_2d_df, columns=['submission_status'], dtype=int)\n",
    "        .groupby('user_id')\n",
    "        .agg(\n",
    "            nuniq_step_subm=('step_id', 'nunique'),\n",
    "            nuniq_correct_step=('submission_status_correct', 'nunique'),\n",
    "            cnt_correct=('submission_status_correct', 'sum'),\n",
    "            cnt_wrong=('submission_status_wrong', 'sum'),\n",
    "            nuniq_days_subm=('day', 'nunique')\n",
    "        )\n",
    "        .reset_index()\n",
    ")\n",
    "\n",
    "# Добавляем таблицу признаков в датасет для обучения\n",
    "total_df = total_df.merge(feature_df, on='user_id', how='outer').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ecebd62-af28-4d03-8c43-1495fe3502a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распределение целевой переменной:\n",
      " more_40  count\n",
      "       0  17269\n",
      "       1   1965\n",
      "\n",
      "Доля пользователей, набравших больше 40 баллов: 0.102\n"
     ]
    }
   ],
   "source": [
    "print(\"Распределение целевой переменной:\")\n",
    "print(\n",
    "    total_df['more_40'].value_counts()\n",
    "        .reset_index()\n",
    "        .astype({'more_40': 'int'})\n",
    "        .to_string(index=False)\n",
    ")\n",
    "print(f\"\\nДоля пользователей, набравших больше 40 баллов: {total_df['more_40'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0558b58e-0799-4e9f-aa23-2b435a46557c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19234 entries, 0 to 19233\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   user_id                19234 non-null  int64  \n",
      " 1   more_40                19234 non-null  float64\n",
      " 2   nuniq_steps_events     19234 non-null  int64  \n",
      " 3   cnt_discovered         19234 non-null  int32  \n",
      " 4   cnt_passed             19234 non-null  int32  \n",
      " 5   cnt_started_attempt    19234 non-null  int32  \n",
      " 6   cnt_viewed             19234 non-null  int32  \n",
      " 7   nuniq_days_events      19234 non-null  int64  \n",
      " 8   correct_on_last_step   19234 non-null  float64\n",
      " 9   wrong_on_last_step     19234 non-null  float64\n",
      " 10  correct_on_first_step  19234 non-null  float64\n",
      " 11  wrong_on_first_step    19234 non-null  float64\n",
      " 12  nuniq_step_subm        19234 non-null  float64\n",
      " 13  nuniq_correct_step     19234 non-null  float64\n",
      " 14  cnt_correct            19234 non-null  float64\n",
      " 15  cnt_wrong              19234 non-null  float64\n",
      " 16  nuniq_days_subm        19234 non-null  float64\n",
      "dtypes: float64(10), int32(4), int64(3)\n",
      "memory usage: 2.2 MB\n"
     ]
    }
   ],
   "source": [
    "total_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af02d79b-0e51-42fd-9532-3ab7e154ae5c",
   "metadata": {},
   "source": [
    "После проделанной работы получили датафрейм со следующими признаками для машинного обучения:\n",
    "- nuniq_steps_events - количество уникальных стэпов с событиями,\n",
    "- cnt_discovered - количество переходов на стэп,\n",
    "- cnt_passed - количество удачных решений стэпа,\n",
    "- cnt_started_attempt - количество попыток решить стэп,\n",
    "- cnt_viewed - количество просмотров стэпов,\n",
    "- nuniq_days_events - число уникальных дней с событиями, \n",
    "- correct_on_last_step - число решений со статусом correct на последнем стэпе,\n",
    "- wrong_on_last_step - число решений со статусом wrong на последнем стэпе,\n",
    "- correct_on_first_step - число решений со статусом correct на первом стэпе,\n",
    "- wrong_on_first_step - число решений со статусом wrong на первом стэпе,\n",
    "- nuniq_step_subm - количество уникальных стэпов со статусами решений,\n",
    "- nuniq_correct_step - количество степов со статусом решений correct,\n",
    "- cnt_correct - количество решений со статусом correct,\n",
    "- cnt_wrong - количество решений со статусом wrong,\n",
    "- nuniq_days_subm - число уникальных дней с решениями."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4227007-4d81-419c-b884-9f827018253f",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Формирование и тестирование моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a278cb1-0c57-484b-8a2e-08a08d76315c",
   "metadata": {},
   "source": [
    "- Подготовка данных для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca202a47-5517-4b13-8a42-5e05112ac4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Подготовка данных для обучения\n",
    "    \"\"\"\n",
    "    # Разделение на train и test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                        test_size=test_size, \n",
    "                                                        random_state=RANDOM_STATE,\n",
    "                                                        stratify=y\n",
    "                                                       )\n",
    "        \n",
    "    print(f\"Размеры данных:\")\n",
    "    print(f\"Train: {X_train.shape}, \\nTest: {X_test.shape}\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac240cb-dde4-44e4-9c09-b5bba0cbbe20",
   "metadata": {},
   "source": [
    "- Настройка XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3932442-15de-4d1c-a1c5-1a7726ca2f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_xgb(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Оптимизация гиперпараметров XGBoost\n",
    "    \"\"\"   \n",
    "    \n",
    "    # расчет scale_pos_weight\n",
    "    class_counts = np.bincount(y_train)\n",
    "    scale_pos_weight = (class_counts[0] / class_counts[1]).round(1)\n",
    "    \n",
    "    xgb_params = {\n",
    "        'n_estimators': [100, 200, 300, 400, 500],\n",
    "        'max_depth': [2, 3, 4, 5, 8], #\n",
    "        'learning_rate': [0.005, 0.01, 0.05, 0.1, 0.15],\n",
    "        'subsample': [0.7, 0.8, 0.9],\n",
    "        'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "        'scale_pos_weight': [scale_pos_weight],\n",
    "        'reg_alpha': [0, 0.1, 0.5, 1],\n",
    "        'reg_lambda': [1, 2, 3, 5]\n",
    "    } \n",
    "\n",
    "    # Стратифицированное разбиение\n",
    "    cv_stratified = StratifiedKFold(\n",
    "        n_splits=CV_FOLDS, \n",
    "        shuffle=True, \n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "    \n",
    "    model_xgb = XGBClassifier(\n",
    "        eval_metric='auc',\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "    \n",
    "    model_xgb_search = RandomizedSearchCV(\n",
    "        model_xgb,\n",
    "        xgb_params,\n",
    "        n_iter=50, \n",
    "        cv=cv_stratified,\n",
    "        scoring='roc_auc',\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    start_time = time()  \n",
    "    print(\"Модель XGBoost обучается...\", end=\"  \")\n",
    "    model_xgb_search.fit(X_train, y_train)\n",
    "    print(\"Ok.\")\n",
    "\n",
    "    duration = time() - start_time\n",
    "    print(f\"Время выполнения: {(duration//60):.0f} мин {(duration%60):.0f} сек\")        \n",
    "    print(f\"Лучшие параметры XGBoost: {model_xgb_search.best_params_}\\n\")\n",
    "    \n",
    "    return model_xgb_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e129bdc-106f-43e7-992b-8f66edecc85d",
   "metadata": {},
   "source": [
    "- Настройка Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec42cf70-f181-4bb3-be94-d0225d80aeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_rfс(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Оптимизация гиперпараметров Random Forest\n",
    "    \"\"\"   \n",
    "\n",
    "    rfс_params = {\n",
    "         'n_estimators': [100, 200, 300, 400],\n",
    "         'max_depth': [3, 5, 7, 10],\n",
    "         'min_samples_split': [10, 15, 20, 30],\n",
    "         'min_samples_leaf': [5, 10, 15, 20],\n",
    "         'max_features': ['sqrt', 'log2', 0.3],\n",
    "         'max_samples': [0.6, 0.7, 0.8, 0.9],\n",
    "         'criterion': ['gini', 'entropy'],\n",
    "         'bootstrap': [True],\n",
    "         'class_weight': ['balanced'],\n",
    "    }\n",
    "\n",
    "    # Стратифицированное разбиение\n",
    "    cv_stratified = StratifiedKFold(\n",
    "        n_splits=CV_FOLDS, \n",
    "        shuffle=True, \n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "    \n",
    "    model_rfс = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "    \n",
    "    model_rfс_search = RandomizedSearchCV(\n",
    "        model_rfс, \n",
    "        rfс_params,\n",
    "        n_iter=70,\n",
    "        cv=cv_stratified,\n",
    "        scoring='roc_auc',\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    start_time = time()  \n",
    "    print(\"Модель Random Forest обучается...\", end=\"  \")\n",
    "    model_rfс_search.fit(X_train, y_train)\n",
    "    print(\"Ok.\")\n",
    "\n",
    "    duration = time() - start_time\n",
    "    print(f\"Время выполнения: {(duration//60):.0f} мин {(duration%60):.0f} сек\")   \n",
    "    print(f\"Лучшие параметры Random Forest: {model_rfс_search.best_params_}\\n\")\n",
    "    \n",
    "    return model_rfс_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc72650-a04e-4da2-99dd-988aeef83f93",
   "metadata": {},
   "source": [
    "- Настройка Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ca4f35d-0602-4f19-9f8a-c73f5c2c815e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_gbc(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Оптимизация гиперпараметров Gradient Boosting\n",
    "    \"\"\"\n",
    "    \n",
    "    gbc_params = {\n",
    "        'n_estimators': [500],\n",
    "        'max_depth':  [2, 3, 4, 5],\n",
    "        'learning_rate': [0.005, 0.01, 0.05, 0.1, 0.15],\n",
    "        'min_samples_split': [20, 50, 70, 100],\n",
    "        'min_samples_leaf': [10, 20, 30], \n",
    "        'subsample': [0.7, 0.8, 0.9],\n",
    "        'max_features': ['sqrt', 'log2', 0.3]\n",
    "    }\n",
    "\n",
    "    # Стратифицированное разбиение\n",
    "    cv_stratified = StratifiedKFold(\n",
    "        n_splits=CV_FOLDS, \n",
    "        shuffle=True, \n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "    \n",
    "    model_gbc = GradientBoostingClassifier(\n",
    "        n_iter_no_change=30,\n",
    "        validation_fraction=0.1,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "    \n",
    "    model_gbc_search = RandomizedSearchCV(\n",
    "        model_gbc, \n",
    "        gbc_params,\n",
    "        n_iter=50,\n",
    "        cv=cv_stratified,\n",
    "        scoring='roc_auc',\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    start_time = time()  \n",
    "    print(\"Модель Gradient Boosting обучается...\", end=\"  \")\n",
    "    model_gbc_search.fit(X_train, y_train)\n",
    "    print(\"Ok.\")\n",
    "    \n",
    "    duration = time() - start_time\n",
    "    print(f\"Время выполнения: {(duration//60):.0f} мин {(duration%60):.0f} сек\")    \n",
    "    print(f\"Лучшие параметры Gradient Boosting: {model_gbc_search.best_params_}\\n\")\n",
    "    \n",
    "    return model_gbc_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803bd1db-483d-4d0a-82f4-7cd5d62a9980",
   "metadata": {},
   "source": [
    "- Настройка CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aec73f50-3d1b-4e5f-8a8a-7bb89e099f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_catb(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Оптимизация гиперпараметров CatBoost\n",
    "    \"\"\"\n",
    "    \n",
    "    catb_params = {\n",
    "        'iterations': [700],\n",
    "        'depth': [2, 4, 6, 8], \n",
    "        'l2_leaf_reg': [1, 2, 3, 5],\n",
    "        'auto_class_weights': ['Balanced'],\n",
    "        'learning_rate': [0.005, 0.01, 0.05, 0.1, 0.15]\n",
    "    }\n",
    "\n",
    "    # Стратифицированное разбиение\n",
    "    cv_stratified = StratifiedKFold(\n",
    "        n_splits=CV_FOLDS, \n",
    "        shuffle=True, \n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "    \n",
    "    model_catb = CatBoostClassifier(\n",
    "        loss_function='Logloss',\n",
    "        early_stopping_rounds=30, \n",
    "        eval_metric='AUC',\n",
    "        verbose=False,\n",
    "        random_state=RANDOM_STATE,\n",
    "        thread_count=-1\n",
    "    )\n",
    "    \n",
    "    model_catb_search = RandomizedSearchCV(\n",
    "        model_catb, \n",
    "        catb_params,\n",
    "        cv=cv_stratified,\n",
    "        scoring='roc_auc',\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    start_time = time()  \n",
    "    print(\"Модель CatBoost обучается...\", end=\"  \")\n",
    "    model_catb_search.fit(X_train, y_train)\n",
    "    print(\"Ok.\")\n",
    "\n",
    "    duration = time() - start_time\n",
    "    print(f\"Время выполнения: {(duration//60):.0f} мин {(duration%60):.0f} сек\")   \n",
    "    print(f\"Лучшие параметры CatBoost: {model_catb_search.best_params_}\\n\")\n",
    "    \n",
    "    return model_catb_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa866d2e-fa25-4835-8da7-100e85db8d98",
   "metadata": {},
   "source": [
    "- Создание ансамбля Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38339517-6b37-4394-8fd9-2eca741f2df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_stacking(list_models, X_train, y_train):\n",
    "    \"\"\"\n",
    "    Создание Stacking\n",
    "    \"\"\"\n",
    "\n",
    "    meta_pipeline = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        LogisticRegression(\n",
    "            C=0.1,\n",
    "            penalty='l2',\n",
    "            max_iter=1000,\n",
    "            random_state=RANDOM_STATE,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "    )\n",
    "        \n",
    "    ens_stacking = StackingClassifier(\n",
    "        estimators=[(name, model) for name, model in list_models.items()],\n",
    "        final_estimator=meta_pipeline,\n",
    "        cv=CV_FOLDS,\n",
    "        passthrough=False,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    start_time = time()  \n",
    "    print(\"Ансамбль Stacking Classifier обучается...\", end=\"  \")\n",
    "    ens_stacking.fit(X_train, y_train)\n",
    "    print(\"Ok.\")\n",
    "\n",
    "    duration = time() - start_time\n",
    "    print(f\"Время выполнения: {(duration//60):.0f} мин {(duration%60):.0f} сек\\n\")    \n",
    "\n",
    "    print(\"Состав ансамбля:\")\n",
    "    for name, model in list_models.items():\n",
    "        print(f\"- {type(model).__name__}\")\n",
    "        \n",
    "    return ens_stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2820376d-0628-41e5-a19d-ef3b24c71c76",
   "metadata": {},
   "source": [
    "- Оценка моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a96c2b5c-eed7-48e8-bf50-a5b982139e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(models, X_train, y_train, cv_n=max(3, CV_FOLDS)):\n",
    "    \"\"\"\n",
    "    Оценка моделей\n",
    "    \"\"\"   \n",
    "    \n",
    "    # Оценка через кросс-валидацию\n",
    "    scores_dic = {}\n",
    "\n",
    "    rskf = RepeatedStratifiedKFold(\n",
    "        n_splits=cv_n, \n",
    "        n_repeats=7, \n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        scores = cross_val_score(\n",
    "            model, \n",
    "            X_train, \n",
    "            y_train, \n",
    "            cv=rskf, \n",
    "            scoring='roc_auc', \n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        scores_dic[name] = {'all_scores': scores}\n",
    "    \n",
    "    scores_df = pd.DataFrame(scores_dic).T\n",
    "    \n",
    "    return scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4715f2-4488-4f71-adca-97e6e209a7c9",
   "metadata": {},
   "source": [
    "- Выбор лучшей модели по нижней границе доверительного интервала ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "147afa1e-fae9-4b12-b2c3-9d4e5dabb640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_model(df, confidence=0.95):\n",
    "    \"\"\"\n",
    "    Выбирает лучшую модель по нижней границе доверительного интервала ROC-AUC\n",
    "    \"\"\"\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for model_name, row in df.iterrows():\n",
    "        scores = row['all_scores']\n",
    "        n_folds = len(scores)\n",
    "        mean_score = np.mean(scores)\n",
    "        std_score = np.std(scores, ddof=1)\n",
    "                \n",
    "        # Расчет доверительного интервала\n",
    "        t_value = stats.t.ppf((1 + confidence) / 2, n_folds - 1)\n",
    "        sem = np.std(scores, ddof=1) / np.sqrt(n_folds)\n",
    "        ci_lower = np.mean(scores) - t_value * sem\n",
    "        ci_upper = np.mean(scores) + t_value * sem\n",
    "        \n",
    "        results.append({\n",
    "            'model': model_name,\n",
    "            'mean_roc_auc': mean_score,\n",
    "            'median': np.median(scores),\n",
    "            'std_roc_auc': std_score,\n",
    "            'n_folds': n_folds,\n",
    "            'ci_lower': ci_lower,\n",
    "            'ci_upper': ci_upper\n",
    "        })\n",
    "    \n",
    "    # Создаем датафрейм с результатами\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.set_index('model', inplace=True)\n",
    "  \n",
    "    # Выбираем модель с максимальной нижней границей CI\n",
    "    best_model_name = results_df['ci_lower'].idxmax()\n",
    "    best_model_metrics = results_df.loc[best_model_name]\n",
    "    \n",
    "    # Сортируем результаты по ci_lower\n",
    "    results_df = results_df.sort_values('ci_lower', ascending=False)\n",
    "    results_df['rank'] = results_df['ci_lower'].rank(method='min', ascending=False)\n",
    "\n",
    "    title_table_models = \"СРАВНЕНИЕ ВСЕХ МОДЕЛЕЙ (отсортировано по CI lower):\"\n",
    "    print()\n",
    "    print(title_table_models)\n",
    "    print(\"-\" * len(title_table_models))\n",
    "    print(results_df.to_string(index_names=False), \"\\n\")\n",
    "\n",
    "    title_best_model = f\"ЛУЧШАЯ МОДЕЛЬ: {best_model_name}\"\n",
    "    print(title_best_model)\n",
    "    print(\"-\" * len(title_best_model))\n",
    "    print(f\"ROC-AUC: {best_model_metrics['mean_roc_auc']:.4f} ± {best_model_metrics['std_roc_auc']:.4f}\")\n",
    "    print(f\"Доверительный интервал ({confidence*100:.0f}%): [{best_model_metrics['ci_lower']:.4f}, {best_model_metrics['ci_upper']:.4f}]\")\n",
    "\n",
    "    # Анализ качества модели\n",
    "    quality = (\"ОТЛИЧНОЕ\" if best_model_metrics['mean_roc_auc'] > 0.9 else \n",
    "                   \"ХОРОШЕЕ\" if best_model_metrics['mean_roc_auc'] > 0.8 else \"ТРЕБУЕТ ДОРАБОТКИ\")\n",
    "    \n",
    "    print(f\"Качество модели: {quality}\")\n",
    "    \n",
    "    # Анализ стабильности\n",
    "    cv = best_model_metrics['std_roc_auc'] / best_model_metrics['mean_roc_auc']\n",
    "    stability_level = (\"ОТЛИЧНАЯ\" if cv < 0.05 else \n",
    "                           \"ХОРОШАЯ\" if cv < 0.1 else \n",
    "                               \"УМЕРЕННАЯ\" if cv < 0.25 else \"НИЗКАЯ\")\n",
    "    \n",
    "    print(f\"Стабильность: {stability_level} (коэф. вариации: {cv:.4f})\")\n",
    "    \n",
    "    # Дополнительная информация о выборе\n",
    "    title_justification = \"ОБОСНОВАНИЕ ВЫБОРА:\"\n",
    "    print()\n",
    "    print(title_justification)\n",
    "    print(\"-\" * len(title_justification))    \n",
    "    print(f\"Модель '{best_model_name}' выбрана, потому что имеет\")\n",
    "    print(f\"наивысшую нижнюю границу доверительного интервала ({results_df.loc[best_model_name,'ci_lower']:.4f}),\")\n",
    "    print(f\"что означает наибольшую гарантированную производительность с уверенностью {confidence*100:.0f}%.\")\n",
    "\n",
    "    return best_model_name, results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4752d8e-aeff-45ce-8b26-326cddaac82a",
   "metadata": {},
   "source": [
    "- Полный пайплайн обучения и оценки моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41e8039d-8c14-4c3d-b9f0-140feeed8952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_pipeline(X, y):\n",
    "    \"\"\"\n",
    "    Полный пайплайн обучения и оценки моделей\n",
    "    \"\"\"\n",
    "    # 1. Подготовка данных\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ПОДГОТОВКА ДАННЫХ\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "    \n",
    "    # 2. Оптимизация всех моделей\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"НАСТРОЙКА МОДЕЛЕЙ\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    list_models = {\n",
    "        'XGBoost': ml_xgb,\n",
    "        'RandomForest': ml_rfс,\n",
    "        'GradientBoosting': ml_gbc,\n",
    "        'CatBoost': ml_catb\n",
    "    }\n",
    "\n",
    "    models = {}\n",
    "\n",
    "    for name, func in list_models.items():\n",
    "        models[name] = func(X_train, y_train)\n",
    "\n",
    "    # 3. Создание ансамбля\n",
    "    print(\"=\" * 80)\n",
    "    print(\"СОЗДАНИЕ АНСАМБЛЯ\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    models['Stacking'] = ml_stacking(models, X_train, y_train)\n",
    "    \n",
    "    # 4. Оценка всех моделей и выбор лучшей\n",
    "    print(\"=\" * 80)\n",
    "    print(\"РЕЗУЛЬТАТЫ ВЫБОРА МОДЕЛИ ПО НИЖНЕЙ ГРАНИЦЕ ДОВЕРИТЕЛЬНОГО ИНТЕРВАЛА\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # 4.1 Оценка через кросс-валидацию\n",
    "    train_scores_df = evaluate_model(models, X_train, y_train)\n",
    "    \n",
    "    # 4.2 Выбираем лучшую модель\n",
    "    best_model_name, results_df = select_model(train_scores_df)\n",
    "    best_model = models[best_model_name]   \n",
    "    \n",
    "    # 5. Финальная оценка на тесте с лучшей моделью\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ФИНАЛЬНАЯ ОЦЕНКА НА ТЕСТЕ\")\n",
    "    print(\"=\" * 80)   \n",
    "    \n",
    "    test_roc_auc = roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1])\n",
    "    \n",
    "    print(f\"Лучшая модель: {best_model_name}\")\n",
    "    print(f\"Test ROC-AUC: {test_roc_auc:.4f}\")\n",
    "   \n",
    "    return {\n",
    "        'models': models,\n",
    "        'best_model_name': best_model_name,\n",
    "        'best_model': best_model,\n",
    "        'test_roc_auc': test_roc_auc,\n",
    "        'comparison_models': results_df\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4a3943e-5123-497d-9725-f787da2c526c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделяем датасет на признаки и целевое значение\n",
    "X = total_df.drop(['user_id', 'more_40'], axis=1)\n",
    "y = total_df['more_40']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "230c5ba9-5e41-4047-82a5-83cf30b1f508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ПОДГОТОВКА ДАННЫХ\n",
      "================================================================================\n",
      "Размеры данных:\n",
      "Train: (15387, 15), \n",
      "Test: (3847, 15)\n",
      "\n",
      "================================================================================\n",
      "НАСТРОЙКА МОДЕЛЕЙ\n",
      "================================================================================\n",
      "Модель XGBoost обучается...  Ok.\n",
      "Время выполнения: 0 мин 35 сек\n",
      "Лучшие параметры XGBoost: {'subsample': 0.7, 'scale_pos_weight': 8.8, 'reg_lambda': 1, 'reg_alpha': 1, 'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.01, 'colsample_bytree': 0.9}\n",
      "\n",
      "Модель Random Forest обучается...  Ok.\n",
      "Время выполнения: 1 мин 35 сек\n",
      "Лучшие параметры Random Forest: {'n_estimators': 300, 'min_samples_split': 15, 'min_samples_leaf': 10, 'max_samples': 0.9, 'max_features': 0.3, 'max_depth': 7, 'criterion': 'entropy', 'class_weight': 'balanced', 'bootstrap': True}\n",
      "\n",
      "Модель Gradient Boosting обучается...  Ok.\n",
      "Время выполнения: 1 мин 24 сек\n",
      "Лучшие параметры Gradient Boosting: {'subsample': 0.9, 'n_estimators': 500, 'min_samples_split': 70, 'min_samples_leaf': 30, 'max_features': 'sqrt', 'max_depth': 5, 'learning_rate': 0.005}\n",
      "\n",
      "Модель CatBoost обучается...  Ok.\n",
      "Время выполнения: 2 мин 25 сек\n",
      "Лучшие параметры CatBoost: {'learning_rate': 0.01, 'l2_leaf_reg': 1, 'iterations': 700, 'depth': 4, 'auto_class_weights': 'Balanced'}\n",
      "\n",
      "================================================================================\n",
      "СОЗДАНИЕ АНСАМБЛЯ\n",
      "================================================================================\n",
      "Ансамбль Stacking Classifier обучается...  Ok.\n",
      "Время выполнения: 0 мин 35 сек\n",
      "\n",
      "Состав ансамбля:\n",
      "- XGBClassifier\n",
      "- RandomForestClassifier\n",
      "- GradientBoostingClassifier\n",
      "- CatBoostClassifier\n",
      "================================================================================\n",
      "РЕЗУЛЬТАТЫ ВЫБОРА МОДЕЛИ ПО НИЖНЕЙ ГРАНИЦЕ ДОВЕРИТЕЛЬНОГО ИНТЕРВАЛА\n",
      "================================================================================\n",
      "\n",
      "СРАВНЕНИЕ ВСЕХ МОДЕЛЕЙ (отсортировано по CI lower):\n",
      "---------------------------------------------------\n",
      "                  mean_roc_auc    median  std_roc_auc  n_folds  ci_lower  ci_upper  rank\n",
      "Stacking              0.891521  0.892496     0.006937       35  0.889138  0.893904   1.0\n",
      "XGBoost               0.891154  0.891576     0.006938       35  0.888770  0.893537   2.0\n",
      "GradientBoosting      0.891194  0.893000     0.007100       35  0.888756  0.893633   3.0\n",
      "RandomForest          0.890981  0.893424     0.006999       35  0.888577  0.893385   4.0\n",
      "CatBoost              0.890336  0.891687     0.007068       35  0.887908  0.892764   5.0 \n",
      "\n",
      "ЛУЧШАЯ МОДЕЛЬ: Stacking\n",
      "-----------------------\n",
      "ROC-AUC: 0.8915 ± 0.0069\n",
      "Доверительный интервал (95%): [0.8891, 0.8939]\n",
      "Качество модели: ХОРОШЕЕ\n",
      "Стабильность: ОТЛИЧНАЯ (коэф. вариации: 0.0078)\n",
      "\n",
      "ОБОСНОВАНИЕ ВЫБОРА:\n",
      "-------------------\n",
      "Модель 'Stacking' выбрана, потому что имеет\n",
      "наивысшую нижнюю границу доверительного интервала (0.8891),\n",
      "что означает наибольшую гарантированную производительность с уверенностью 95%.\n",
      "\n",
      "================================================================================\n",
      "ФИНАЛЬНАЯ ОЦЕНКА НА ТЕСТЕ\n",
      "================================================================================\n",
      "Лучшая модель: Stacking\n",
      "Test ROC-AUC: 0.8915\n"
     ]
    }
   ],
   "source": [
    "results = full_pipeline(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25efc80a-e336-4aae-8c88-3bb2c5c2fa18",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Общий вывод и рекомендации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3f0d7d-7c7f-43f2-9b3a-bc34ae8c617a",
   "metadata": {},
   "source": [
    "##### В данной работе проанализированы данные о решениях и действиях для 19234 студентов за первые два дня прохождения курса (с момента начала первого решения), удалены дубликаты и созданы дополнительные признаки для обучения моделей.\n",
    "\n",
    "Датасет для анализа содержит 19234 строк (студентов), 15 различных признаков и целевую переменную. Для предсказания наберет студент 40 баллов или нет, мы использовали алгоритмы: XGBClassifier, RandomForestClassifier, GradientBoostingClassifier, CatBoostClassifier и ансамбль Stacking. \n",
    "\n",
    "Все модели показали практически одинаковые результаты. Лучшая модель на основе максимальной нижней границы доверительного интервала ROC-AUC - ансамбль Stacking. На тестовой выборке результат ROC-AUC - 0.8915.\n",
    "\n",
    "Для увеличения метрики качества можно составить дополнительные признаки, попробовать другие алгоритмы или увеличить количество анализируемых дней, по которым строим метрики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feff3f6-6d67-4a47-b5a6-68e97603b768",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
